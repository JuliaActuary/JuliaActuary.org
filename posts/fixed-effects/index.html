<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.45">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="JuliaActuary is an ecosystem of packages that makes Julia the easiest language to get started for actuarial workflows.">

<title>Fixed Effects Model Example – JuliaActuary</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../..//assets/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="../../assets/highlight/styles/github.min.css">
<script src="../../assets/highlight/highlight.min.js"></script>
<script src="../../assets/highlight/languages/julia.min.js"></script>
<script src="../../assets/highlight/languages/julia-repl.min.js"></script>
<script src="../../assets/highlight/languages/python.min.js"></script>
<script src="../../assets/highlight/languages/r.min.js"></script>
<script>hljs.highlightAll();</script>
<script data-goatcounter="https://juliaactuary.goatcounter.com/count" async="" src="//gc.zgo.at/count.js"></script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../assets/logos/android-chrome-512x512.png" alt="JuliaActuary Logo" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">JuliaActuary</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../packages.html"> 
<span class="menu-text">Packages</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../learn.html"> 
<span class="menu-text">Learn</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../examples.html"> 
<span class="menu-text">Examples</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../benchmarks.html"> 
<span class="menu-text">Benchmarks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../community.html"> 
<span class="menu-text">Learn</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/JuliaActuary"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../all-posts.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Fixed Effects Model Example</h1>
                  <div>
        <div class="description">
          JuliaActuary is an ecosystem of packages that makes Julia the easiest language to get started for actuarial workflows.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">modeling</div>
                <div class="quarto-category">statistics</div>
                <div class="quarto-category">experience-analysis</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>These examples and description is based very heavily on this <a href="https://youtu.be/iwVqiiXYeC4&amp;t=3304">bonus lecture from Richard McElreath</a></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Transcript of Relevant section from McElreath’s lecture video
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Transcribed by open-whisper medium model, with some formatting &amp; paragraph structure by Claude Opus 3.</em></p>
<p>This is the longest requested bonus content since I started teaching the course I think more than a decade ago. The topic is how to deal with confounding and the estimation under partial pooling. I’m going to need some background here, understand what’s going on. So it’s often plausible that there are unmeasured confounds at the group level, that is some aspect of the group that is a confound because it influences the outcome variable of interest and the treatment of interest. So if you look at the DAG on the right of this slide, you’ll see that we’re thinking about the tadpoles, I’ll explain this in some detail in a second. G is our unobserved group feature, or probably more than one feature, and there are arrows going both to the outcome S and to the treatment X. So it’s a confound, it creates a backdoor path. And we know that we want to close backdoor paths, but we haven’t measured G. Well, there’s some tricks up our sleeves when we have repeat observations. This literature is very confusing, which is why I’m often asked to talk about it, because every field and even every subfield uses different terminologies and seems to have a different modeling preference. So it’s incredibly confusing. These are often sometimes called group level confounding. The word endogeneity gets thrown around as if that resolved the ambiguity. Correlated errors people talk about. And then there’s this field called econometrics, where all of their terminology is different. The basic issue is the group level variables can have direct and indirect influences, and we need to think about that when we draw our generative models. Let’s build this up one step at a time, and then I’ll show you some of the models that are used in this area and explain the options and the sorts of problems that each addresses. So again, think about the tadpoles, keep things simple. We’ve got unobserved features of the tank that will affect survival, and that’s something that we need to be worried about to estimate other parts of the experiment, the treatment of interest that’s coming. There are also measured features of the group or tank, here I’m going to call them Z. These are things that are features of the tank, so every tadpole in the tank experiences the same Z. This is called a group level variable or group trait. And then there’s the thing of interest, which varies at the individual level. These are things we might measure about each individual tadpole, and we’re interested in the causal effects of those individual level traits on survival. And then the problem can arise that it’s often very plausible that unmeasured features of the cluster of the group of the tank, in this case, that can influence survival directly, may also influence it indirectly, mediated through the traits of individuals. Yeah, let me give you, wait, so here’s the idea. Our estimate is the distribution of survival, intervening on X, and the problem is there’s a backdoor path through G, so what can we do about that? If you want to think about some examples, maybe tadpoles aren’t your favorite thing and you can’t think about how this would work, but it could be that there’s some feature of the tank like temperature that affects individual growth and also immediately survival, and so it has two routes towards affecting survival, both through long-term effects on individuals and immediate effects on individuals at the time of death. Often this literature talks about classrooms because these sorts of models are used a lot in measuring student progress and doing teacher evaluations, and so you can think about the clusters now as being classrooms, and classrooms have lots of things about them that make them different from one another, and many of them are unmeasured or even unimagined, and we’re interested in the effect of student preparation, which has got a subscript I on it because it applies to each individual student, and test scores, S sub I, which again is a feature of the individual student, and then there are measured things about the classrooms like temperature Z at the bottom. What could be unmeasured about classrooms, it could be noisy classrooms that directly reduce test scores because it’s hard to take the test in the noisy classroom, but noisy classrooms could also reduce student preparation, and so there could be a direct and indirect effect. Political scientists are interested in time-varying versions of this problem, where the individuals are individual time points, and they’re clustered by country or nation, and so for example, people might ask how, which party is ruling a country at any point in time T, how that influences the economy at T or sometime after T, and there are things we measured about the resources or infrastructure of these countries that we think might influence the economy as well, be a competing cause, but there are lots of unmeasured things, possibly, that we haven’t even imagined, and those things might influence both who becomes a ruling party and the economy directly. For example, when the economy takes a certain state, through these influences, those influences might simultaneously result in certain styles of politics becoming popular. Okay, so what do we do? We’ve got our estimate, we want to measure the influence of X on Y, and we know there’s a confound G, we believe there’s a confound G, it’s often a good assumption, and so what can we do, and this is one of those cases where there are multiple estimators and they all have trade-offs, and I want to walk you through the issues involved. The first one is the so-called fixed effects model, this is very popular in lots of fields actually, and it’s a reasonable choice, I’m not going to tell you not to use it, but it’s got some drawbacks, and I want to explain those to you, I also want to explain to you why it can work. The second is a multi-level model, and I’m going to show you what the sort of naive multi-level model which is not, doesn’t take the confounds into account, what it does, how it behaves in this circumstance, and then we’re going to fix the naive multi-level model, well fix it, it wasn’t broken in the first place, the naive multi-level model just didn’t account for the confounding, so we’re going to use a multi-level model that does, and I like to call these MUNLAC machines, MUNLAC was a man, he was an agricultural economist who was interested in these problems. Okay, so to do this, we want to simulate some data so we know the right answer, so that’s what I’m doing on this slide, the code at the top, I’ve got 30 groups, and you can think about these as tadpoles if you like, where y will be survival, and x will be some feature of the tadpole like it’s health, and z is something else we measure about it, or you can think about it as students in classrooms, where y is test scores and x is how much they study, and the unmeasured g things are unmeasured things about the classrooms, and z is the teacher, or something like that, and so we have 30 groups, tanks or classrooms, 200 tadpoles or students, and I create some regression parameters there at the top, the minus two is the overall rate of the outcomes, this is a binary outcome, so it happens less than half the time across all the units, and then I create an effect for z on y and I have it be slightly negative minus point five, and then that lowercase g vector I just sample tadpoles in the tanks or students into groups at random, this means that some groups have more tadpoles slash students than others, and you can see the table of that on the bottom, right, so there are some groups like group number one has 11, but group number two only has five students, and then the u sub g’s are our unobserved confounds, the u for unobserved and the g subscript that there’s one for each group, and I just sample those, and they vary quite a bit across groups, the standard deviation of 1.5, then sample the x’s, these are individual level variables, there’s one for each individual tadpole slash student, but their mean is the unobserved confounds in each group, I’ll say that again, we sample the individual x’s, there’s 200 of them, but the mean in each group is that unobserved u sub g, yeah, and that’s where the confounding comes in, is that the individual level traits are caused partly by those that unobserved group confound, or group variable, then simulate disease and then finally, the master equation at the bottom there, this is just a random Bernoulli variable, where the probability of each y sub i is the sum of all those things, where there’s some global intercept alpha zero, which again is i set to minus two, so that the event usually doesn’t happen, net the other effects, and then x, now notice I just add x here, which means it’s coefficient is one, and we’re going to want to keep that in mind as we look through the following slides, and then the confound, and again, I make it just as strong as x, for the sake of the example, so the confounding is obvious, you can make the confounding weak and then you could ignore the whole problem, right, so I want to give you a case where it’s strong, and then we add the z, yeah, and the z made its coefficient slightly negative minus .5. Okay, let’s make some models, first the fixed effects model, and the fixed effect model, what you do is you do what we’ve been doing since the beginning of the course, you have all these units, groups, and you’re going to treat their index as a, create a categorical index for the groups, and you’re going to make a big vector of, of intercept parameters of alphas, we’ve been doing this for a long time, I didn’t, that those models are often called fixed effects models, and the idea is you have repeat observations within each of those clusters, and you estimate a unique alpha for each, but you do it without pooling, so the no pooling, so it’s a fixed prior, and in non-basin approaches, the prior has an infinite variance even, right, we’re not going to do something that silly, but it’s a fixed prior, and so you don’t get any pooling, so the alphas only are only learned from the data within each group, at the prior, and these models can work, I’m going to show you in a second that this can de-confound, and the reason is actually pretty weird, but they’re inefficient because there’s no pooling, but that inefficiency actually allows them to soak up the confounding effect, right, and the reason is because the intercepts essentially fit the average confounding effect, because there’s one intercept for all of the individuals in the group, and remember the confound was just added in the generative simulation, I’ll go back to the previous slide and show it to you, so you look at the line that generates Y, you see that the unobserved UG is just added in there, and so when we estimate alpha, we’re estimating that value, and that’s why it works. Clever, huh? The problem here, well there’s multiple problems, the first problem is, as I said, it’s inefficient, we’d like some pooling on these alphas, but we’ll get to that in a few slides, the second problem, excuse me, my voice is going here, the second problem is when we do this, when we use fixed effects, we can’t include Z, I’ll say that again, when we use fixed effects, we can’t include Z, and that’s because it becomes unidentifiable to separate the effect of Z from the global intercept, because they’re both just added to every prediction within each group, you look at the model on the right, for prediction of every case I, there’s alpha GI, and there’s ZGI times some coefficient, and so the values of those two parameters, alpha G and the alpha for each group, and beta Z times the Z of each group, there’s just an infinite number in principle of combinations of parameter values that’ll fit, and so only the prior ends up mattering in this case, and I’ll show you the consequence of that, and so what you’ll read in like econometric textbooks is that you just can’t include group level predictors, the group level predictors are sometimes the whole research question, yeah, like teacher effects or something like that, and in that case, you’re sunk, and the fixed effect strategy actually blocks you from being able to progress. Here’s what it looks like in ULAM code, I don’t think there’ll be any surprises here, because these are just a categorical model like we did in the second week of the course, and then at the bottom of the slide, I show you the posterior distribution samples from the posterior distributions for the fixed model in the dark black line, that’s the model we’re looking at, the fixed effects model, and the gray density is a model that I’m going to call the naive model, and I haven’t shown you code for that, but that’s just the model, if you took the model, the fixed effects model, and you took the subsetting off of alpha so that there’s the same alpha for every group, that’s naive model, it’s the model that ignores the group differences completely, yeah, and just uses X and Z for each group as ordinary predictors, and unsurprisingly that model is confounded, so if you look at the lower left densities, the vertical dashed line is the true effect we know from the generative model, now we don’t expect any particular sample to exactly get that, but we’d like the high density regions of the posterior distributions to cover the true value, I’ll say that again, should never expect any particular sample to exactly and precisely give you the true data generating value, but it’d be nice if most of the time, the posterior distributions, the high density regions of the posterior distributions are over the true values, yeah, and we see that’s true for the fixed effect model in the lower left, but it’s not for the naive model, and that’s just the expected effect of the confounding, it’s the effect is overestimated because it’s getting like a double dose, right, it’s getting it from the XIs, and it’s getting it from the UGs, and then the naive model ignores the group differences, but the fixed effect model nets out that constant effect by putting it into the intercepts, and then in the lower left we look at the coefficient estimates for Z, and this is the flip side, naive model gets it right on the money, it does a fantastic job estimating the group level of Causse, but the fixed effect model is hopeless here, right, it knows nothing, absolutely nothing, and that’s because what I told you of this effect, that it can’t separate the intercepts from the coefficient on Z, and it’s a completely undetermined sort of modeling problem, this is well known by the way, and fixed effect models just don’t allow you to insert, to include group level predictors. Okay, multi-level model, multi-level model’s got a different problem, and that is that it ignores the confound, well it doesn’t ignore it, it often does better than the naive model, but it’s still subject to more confounding because of the partial pooling, right, which is a good thing, remember I keep telling you we like partial pooling and we do, we really do, but the partial pooling pulls the intercepts towards one another, remember, especially for groups that don’t have a lot of individuals in them, a lot of tadpoles or students, and as a consequence it compromises on identifying the confound so that it can get better estimates of the average tendencies of the group, and there’s lots of things, not just the confound that vary by group, and some of them are just pure direct effects, so the intercept is a mix of a lot of things in principle, and so maybe we want a good estimate of it, but the multi-level model is essentially designed ignoring the confound in a way, and even though on average it does better than the naive model, it won’t do as well as the fixed effects model on average, but it often does pretty well, surprisingly, you can try some simulations and see, but I’m going to show you a case where it does worse, because that’s the expectation, so you get better estimates for the groups, the average tendencies of the groups, the unmeasured features of groups, and a worse estimate for X, which is weird, right, but you can include group level predictors, which, you know, again, may be the whole point of your research would be things that apply to the group, so let me show you what the code looks like and show you how it does, so again, upper left here’s the code, there’s a little bit of weird machinery in this ULAM model that I’m going to teach you next week, and I apologize for breaking up the timeline here, but getting this model to run appropriately requires this technique called non-centered priors, and that’s all that’s going on there, but if you just ignore that transparse line, you can read the model normally, and this is just a plain multi-level model, there’s an alpha for each group, and we use partial pooling, there’s an alpha bar, and I call it tau instead of sigma, but it’s just a scale parameter, just like sigma, this is standard deviation across groups, and we include X and the Z, and we run this, and you see at the bottom the updated posterior distributions, in the lower left the effect of X on Y, and you can see it’s a little better than the naive model by distinguishing the groups, but it’s not as good as the fixed effects model, it’s been only, it’s a compromise between the two, just as partial pooling is a compromise between the fixed effects model and the naive model, so in some sense this is obvious in hindsight, in the lower right the multi-level model identifies Z, and just like the naive model does, there’s been no change there. Okay, so people have known about this kind of problem in this trade-off for a long time, about the fixed effects models being better at removing group level confounding, but multi-level models being better at estimation, and therefore prediction, so if you were purely interested in prediction, there’d be no reason to use the fixed effects model, right, but if you’re interested in inference on do X, right, a causal inference for the effect of X, or some other variable, then you might want to use the fixed effects model, and just not care about predictive accuracy at the group level, but you can have your cake and eat it too, and I’m going to introduce you two more models, and then I’m done here. The first I call this the Munlack machine, and Munlack was a man, I said he’s an agricultural economist, give you the citation to the paper on the bottom, this is a very difficult paper to read if you’re not trained in statistics, I’m afraid, but there’s lots of other papers that cite it, that explain it very well, and so if you’re interested in this literature, I would do a citation search on Munlack and find another paper that explains his paper. That said, I’m going to try to explain the key insight to you right here. So what the Munlack machine does, you look at the dag on the right of this slide, is it notes that we have something else, we have an average X within each group, so you take up all the XIs that are in any particular group, little g, and you average them, you’ve got this thing, X bar, which is the average, and that’s also a descendant of the unobserved confound, and so it gives us information about it. So if we condition on that descendant on X bar for each group and treat it like a group level variable, that will partly de confound. Yeah, the inference of the influence of X sub i on Y sub i. Yeah, because remember conditioning on a descendant is is like conditioning on the parent taught you this and I think it was week two or week three. It was week three, but is not as effective. Yeah, because X bar is not a copy of the unmeasured aspects in the circle with G there. So this this works. It’s got some inefficiencies, but you get to have partial pooling. So you get grew good group effects, you get a more de confounded, a better de confounded treatment effective X, X sub i that is. But there’s a new in a new problem here is that this is not very efficient, because this is not a proper way to respect the uncertainty in X bar, we don’t actually know X bar, I mean, you think you know X bar, you just average the data. But look, it the uncertainty in it varies by groups, some groups have a dozen individuals in them in the simulation I showed you and some have three. We’re ignoring the variation in the quality of the measurement of X bar cross groups when we include it like a known variable like this. So we’re going to fix that too, but hang on. All right, so you get this big loget prediction equation at the bottom there. And on the far right, you’ll see that I’ve added a new beta coefficient for X bar. And we just include X bar as the data point. And this is the mud lack machine. And it’s genius, actually, it’s genius. And there’s a code for it up top. I construct X bar just by looping over groups and using the mean function. And you just drop it in his data. And then we update the posterior distributions at the bottom and I’ve drawn mud lack in blue. And you’ll see mud lack is in this particular example very de confounded. He’s flown over to the other side a little bit. But there’s a lot of probability density over the true value. This is this is not a terrible job. And unlike still can model group level effects, you’ll see on the right, it’s piling up with all the others, it’s only the fixed effects model that sucks at estimating Z. Okay, one more. And then I’m done. Let’s fix the problem of improperly respecting the uncertainty in X bar. This is an example of this full luxury base thing that I’ve shown you in multiple bonus rounds, I think so far. This is my joking language is meant to be ironic. But the idea is we take the generative model to tag and we express all of its relationships in a single Markov chain. That’s the idea. You could call this the latent mud lack machine because we don’t include X bar is data, but we estimate X bar using the observed Xi’s. Yeah, and then we get a posterior distribution for it. And we can include that as a predictor. So in principle, what this means is we’ve run two simultaneous regressions. Yeah, so let me, let me split up this tag and show you what I mean. We’re going to have a model for Y. And in the, it says at the top of the screen. And so the code in the upper left, this is the Bernoulli outcome Y. And it is influenced by unmeasured group things alpha for each group. And also then the Xi and then Z. And then on the end of this line, I’ve added this U for each G. This is the unobserved confound that we’d like to estimate. And this is just a parameter. Yeah, but don’t panic. We’re going to estimate. And then I have this transparse line again, which I said, don’t look, I’ll explain that to you next week. And then the X model, the X model in the middle, X is only influenced by the confound, right? That was the generative model, that’s the assumption. And so this is an ordinary linear regression, X is a metric variable. And it’s just this just a linear regression with some intercept AX. And then we modeled the influence of this unobserved group level variable U for each G. And those are defined as just a vector there, right? I see we have a vector of length in G, which is the number of groups. And I assign each of those U values in normal zero one prior. Now, since it’s a latent variable, you can assign it almost any prior you like. Yeah, because it has no metric that you can measure. And then there’s a bunch of priors at the bottom and those are standard. This seems weird, I know, but again, it’s perfectly legitimate models like this are used all the time. This is basically a latent measurement error model. The idea is, we have some measurements, the each of the X of I’s, which gives us information about the group mean for those X’s. But we haven’t observed the group mean. And so we’re estimating it. And that group mean is U for each group G. Yeah, so really, this is like a measurement error model. Yeah, so oh, I should have highlighted this already. So you see, yes, there’s the U for each G appears in both of the equations. Yeah, and it’s in both of the decks. And we can estimate it. And you’ll see here now, the latent mudlack machine I’ve drawn in green, I appreciate that this is one of the ugliest figures from the course so far. But don’t worry, I’ll I’ll aspire to do something even worse in future lectures. But just focus on the green one for now. And you’ll see that’s the mudlack machine, high density region is over the true effect for X. And for Z, this is your best option, by far, if you’ve got the Bayesian horsepower to do it. All right, let me summarize. Should you use fixed effects? Yeah, I mean, sure, there are times when it’s fine. I mean, if you’re not, if you don’t, if you’re not interested in group level predictors, and you’re not interested in prediction, no problem. Yeah, go ahead and do it. Should you include average X, that is the mudlack machine. Often that works fine. If you don’t have the Bayesian horsepower, it’ll work quite well. It’s better than ignoring the group level confounding for sure. But these days, you might as well do the latent model. Everybody’s got the horsepower to do this. And you know, if you know how to do it, go ahead and do it. I don’t see any major obstacle anymore. A decade ago, I might as has something different, because lots of people didn’t have convenient software to do these latent measurement error models. But now it’s really standard in lots of fields. And I advise you just to do that. But in any case, there’s other kinds of confounding, both at the individual level, time varying confounding, all kinds of stuff. And you shouldn’t assume that any of the things I’ve showed you in this bonus round apply to all kinds of group level confounding. What you need to do is draw your assumptions, make a generative model, develop a solution, if one is possible, that way, for your bespoke purpose. Yeah. Okay, thank you.</p>
</div>
</div>
<div id="2" class="cell" data-execution_count="1">
<pre class="julia cell-code"><code>using Distributions
using LogExpFunctions
using StatsBase
using Turing, MCMCChains
using CairoMakie
using Logging;
Logging.disable_logging(Logging.Warn);</code></pre>
</div>
<div id="4" class="cell" data-execution_count="1">
<pre class="julia cell-code"><code>N_groups = 50
N_id = 700
a0 = -2
bZY = -0.5
bXY = 1.0
g = sample(1:N_groups, N_id) # sample into groups
Ug = rand(Normal(1.5, 1), N_groups) # group confounds
X = rand.(Normal.(Ug[g])) # individual varying trait
Z = rand(Normal(0, 1), N_groups) # group varying trait (observed)
Y = @. rand(Bernoulli(logistic(a0 + bXY * X + Ug[g] + bZY * Z[g])))</code></pre>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>700-element BitVector:
 1
 1
 0
 1
 1
 1
 1
 0
 1
 0
 ⋮
 1
 1
 1
 1
 1
 0
 1
 1
 0</code></pre>
</div>
</div>
<div id="6" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code to Plot the Chains’ trace</summary>
<pre class="julia cell-code"><code>function trace(chns, real_param=Dict(:bx =&gt; bXY, :bz =&gt; bZY))
    params = names(chns, :parameters)

    n_chains = length(MCMCChains.chains(chns))
    n_samples = length(chns)
    n_params = length(params)

    colors = to_colormap(:tol_vibrant)
    width = 600
    height = max(400, 80 * n_params)

    fig = Figure(; size=(width, height))

    for (i, param) in enumerate(params)
        ax = Axis(fig[i+1, 1]; ylabel=string(param))
        for chain in 1:n_chains
            values = chns[:, param, chain]
            lines!(
                ax,
                1:n_samples,
                values;
                label=string(chain),
                color=(colors[chain], 0.7),
                linewidth=0.7
            )
        end

        hideydecorations!(ax; label=false)
        if i &lt; n_params
            hidexdecorations!(ax; grid=false)
        else
            ax.xlabel = "Iteration"
        end
    end

    for (i, param) in enumerate(params)
        ax = Axis(fig[i+1, 2]; ylabel=string(param))
        for chain in 1:n_chains
            values = chns[:, param, chain]
            density!(
                ax,
                values;
                label=string(chain),
                color=(colors[chain], 0.1),
                strokewidth=1,
                strokecolor=(colors[chain], 0.7)
            )
        end
        vlines!(real_param[param], label="True Parameter")

        hideydecorations!(ax)
        if i &lt; n_params
            hidexdecorations!(ax; grid=false)
        else
            ax.xlabel = "Parameter estimate"
        end
    end

    axes = [only(contents(fig[i+1, 2])) for i in 1:n_params]
    linkxaxes!(axes...)

    Legend(fig[1, 1:2], first(axes), "Chain", orientation=:horizontal, titlehalign=:left, halign=:left, titleposition=:left)

    rowgap!(fig.layout, 10)
    colgap!(fig.layout, 10)

    return fig
end</code></pre>
</details>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>trace (generic function with 2 methods)</code></pre>
</div>
</div>
<section id="fixed-effects-model" class="level2">
<h2 class="anchored" data-anchor-id="fixed-effects-model">Fixed Effects Model</h2>
<div id="8" class="cell" data-execution_count="1">
<pre class="julia cell-code"><code>@model function fixed_effects(Y, X, g, N_groups, Z)
    # Priors
    a ~ Normal(0, 10)
    bx ~ Normal(0, 1)
    bz ~ Normal(0, 1)
    # Group-level effects
    a_g ~ filldist(Normal(0, 10), N_groups)

    # Model
    for i in eachindex(Y)
        logit_p = a + a_g[g[i]] + bx * X[i] + bz * Z[g[i]]
        Y[i] ~ Bernoulli(logistic(logit_p))
    end
end


chain_fixed_effects = sample(fixed_effects(Y, X, g, N_groups, Z), NUTS(), 1000)
trace(chain_fixed_effects[[:bx, :bz]])</code></pre>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="mulitlevel-model" class="level2">
<h2 class="anchored" data-anchor-id="mulitlevel-model">Mulitlevel Model</h2>
<div id="10" class="cell" data-execution_count="1">
<pre class="julia cell-code"><code>@model function multilevel(Y, X, g, N_groups, Z)
    # Priors
    ᾱ ~ Normal(0, 1)
    τ ~ Exponential(1)
    bx ~ Normal(0, 1)
    bz ~ Normal(0, 1)
    # Group-level effects
    α_g ~ filldist(Normal(ᾱ, τ), N_groups)

    # Model
    for i in eachindex(Y)
        logit_p = α_g[g[i]] + bx * X[i] + bz * Z[g[i]]
        Y[i] ~ Bernoulli(logistic(logit_p))
    end
end

chain_multilevel = sample(multilevel(Y, X, g, N_groups, Z), NUTS(), 1000)

trace(chain_multilevel[[:bx, :bz]])</code></pre>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-6-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="mundlak-model" class="level2">
<h2 class="anchored" data-anchor-id="mundlak-model">Mundlak Model</h2>
<div id="12" class="cell" data-execution_count="1">
<pre class="julia cell-code"><code>@model function mundlak(Y, X, g, N_groups, Z)
    x̄ = [mean(X[g.==i]) for i in 1:N_groups]

    # Priors
    ᾱ ~ Normal(0, 1)
    τ ~ Exponential(1)
    bx ~ Normal(0, 1)
    bz ~ Normal(0, 1)
    bx̄ ~ Normal(0, 1)
    # Group-level effects
    α_g ~ filldist(Normal(ᾱ, τ), N_groups)

    # Model
    logit_p = @. α_g[g] + bx * X + bz * Z[g] + bx̄ * x̄[g]
    Y .~ Bernoulli.(logistic.(logit_p))
end

chain_mundlak = sample(mundlak(Y, X, g, N_groups, Z), NUTS(), 1000)

trace(chain_mundlak[[:bx, :bz]])</code></pre>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-7-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="mundlak-latent-model" class="level2">
<h2 class="anchored" data-anchor-id="mundlak-latent-model">Mundlak Latent Model</h2>
<div id="14" class="cell" data-execution_count="1">
<pre class="julia cell-code"><code>@model function mundlak_latent(Y, X, g, N_groups, Z)

    # Priors
    α_x ~ Normal(0, 1)
    bu_x ~ Exponential(1)
    τ ~ Exponential(1)
    σ ~ Exponential(1)
    ᾱ ~ Normal(0, 1)
    bx ~ Normal(0, 1)
    bz ~ Normal(0, 1)
    bu ~ Normal(0, 1)

    # Group-level effects
    α_g ~ filldist(Normal(ᾱ, τ), N_groups)
    u ~ filldist(Normal(0, 1), N_groups)

    # Model
    # X model
    μ = @. α_x + bu_x * u[g]
    X .~ Normal.(μ, σ)

    # Y model
    logit_p = @. α_g[g] + bx * X + bz * Z[g] + bu * u[g]
    Y .~ Bernoulli.(logistic.(logit_p))
end

chain_mundlak_latent = sample(mundlak_latent(Y, X, g, N_groups, Z), NUTS(), MCMCThreads(), 1000, 4)

trace(chain_mundlak_latent[[:bx, :bz]])</code></pre>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/JuliaActuary\.org");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>