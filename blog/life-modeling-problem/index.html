<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <meta name=Description  content="Practical, extensible, and open-source actuarial modeling and analysis."> <meta property="og:description" content="Practical, extensible, and open-source actuarial modeling and analysis."> <meta property="og:image" content="/assets/logo_square.svg"> <script> MathJax = { tex: { inlineMath: [['$', '$'], ["\\(", "\\)"]], processEscapes: true, } }; </script> <script async src="/assets/MathJax/MathJax-3.2.2/es5/tex-mml-chtml.js"> </script> <style> @font-face { src: url("//assets/MathJax/MathJax-3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff"> } </style> <style> @font-face { src: url("//assets/MathJax/MathJax-3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff"> } </style> <style> @font-face { src: url("//assets/MathJax/MathJax-3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff"> } </style> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.png"> <title>The Life Modeling Problem: A Comparison of Julia, Rust, Python, and R | JuliaActuary</title> <link rel=apple-touch-icon  sizes=180x180  href="/assets/apple-touch-icon.png"> <link rel=icon  type="image/png" sizes=32x32  href="/assets/favicon-32x32.png"> <link rel=icon  type="image/png" sizes=16x16  href="/assets/favicon-16x16.png"> <link rel=manifest  href="/assets/site.webmanifest"> <script src="https://cdn.jsdelivr.net/npm/swiffy-slider@1.2.0/dist/js/swiffy-slider.min.js" crossorigin=anonymous  defer></script> <link href="/css/slider.css" rel=stylesheet > <header> <div class=blog-name > <a href="/"> <div class=blog-name-logo-container > <div class=blog-name-logo > <img src="/assets/logo_square.svg" alt=logo  height=100px  width=100px  /> </div> <div>JuliaActuary</div> </div> </a> <div class=tagline >Practical, extensible, and open-source actuarial modeling and analysis. </div> </div> <nav> <ul> <li><a href="/">Home</a> <li><a href="/packages">Packages</a> <li><a href="/community">Community</a> <ul> <li><a href="/community/#learn">Learn</a> <li><a href="/community/#integration_with_r_and_python">Integration</a> <li><a href="/community/#contributing">Contributing</a> </ul> <li><a href="/#blog">Blog</a> </ul> <img src="/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content ><h1 id=fill_title ><a href="#fill_title" class=header-anchor >The Life Modeling Problem: A Comparison of Julia, Rust, Python, and R</a></h1> <p><em>By: Alec Loudenback</em></p> <p><em>May 16, 2021</em></p> <blockquote> <p><strong>&#33;&#33; Note that this article is a draft</strong></p> </blockquote> <p><em>Note: This is an extended discussion of the results from one of the items on the <a href="/benchmarks/">Benchmarks</a> page.</em></p> <p>In the <a href="https://github.com/actuarialopensource">ActuarialOpenSource</a> GitHub organization, a discussion began of the &quot;Life Modeling Problem&quot; &#40;LMP&#41; in actuarial science.</p> <p>I think the &quot;Life Modeling Problem&quot; has the following attributes:</p> <ul> <li><p>Recursive calculations</p> <li><p>Computationally intensive</p> <li><p>Large volume of data to process</p> </ul> <p>The following discussion will get a little bit technical, but I think there are a few key takeaways:</p> <ol> <li><p>There are a lot of ways to accomplish the same task and and that&#39;s good enough in most cases</p> <li><p>The approach to a problem makes a big difference: &quot;if all you have is a dataframe, everything looks like a join&quot;</p> <li><p>Performance, flexibility, readability: pick one, two, or three depending on the language</p> </ol> <p>To skip the background and the discussion, <a href="#benchmarks">click here to jump to the benchmarks</a>.</p> <h2 id=the_life_modeling_problem ><a href="#the_life_modeling_problem" class=header-anchor >The Life Modeling Problem</a></h2> <p>Inspired by the discussion in the <a href="https://github.com/actuarialopensource">ActuarialOpenSource</a> GitHub community discussion, folks started submitted solutions to what someone referred to as the &quot;Life Modeling Problem&quot;. This user <a href="https://github.com/orgs/actuarialopensource/teams/common-room/discussions/5">submitted a short snippet</a> for consideration of a representative problem.</p> <p>My take on the characteristics are that modeling life actuarial science problems breaks down to the following items:</p> <ul> <li><p>Calculations are recursive in nature</p> <li><p>Computationally intensive calculations</p> <li><p>Performance matters given large volumes of data to process</p> <li><p>Readability and usability aids in controls and risk</p> </ul> <h3 id=recursive_calculations ><a href="#recursive_calculations" class=header-anchor >Recursive calculations</a></h3> <p>Many actuarial formulas are recursive in nature. Reserves are defined &quot;prospectively&quot; or &quot;retrospectively&quot;. Algorithmically, this means that intra-seriatim calculations &#40;ie account value growth, survivorship&#41; are not amenable to parallelism but iter-seriatim calculations would be &#40;ie calculating multiple policy trajectories simultaneously&#41;.</p> <h3 id=computationally_intensive ><a href="#computationally_intensive" class=header-anchor >Computationally intensive</a></h3> <p>Modeling is incredibly computationally complex due to the volume of data needed to process. For example, CUNA Mutual disclosed that they spin up 50 servers with 20 cores a <a href="https://www.cunamutual.com/landing-pages/that-conference/cuna-mutual-applications">couple of days per month</a> to do the calculations.</p> <h3 id=processing_volume ><a href="#processing_volume" class=header-anchor >Processing volume</a></h3> <p>There&#39;s a cottage industry devoted to inforce compression and model simplifications to get runtime and budgets down to a reasonable level. However, as the capacity for computing has grown, the company and regulatory demands have grown. E.g in the US reserving has transition from net-premium reserve to integrated ALM &#40;CFT&#41; to deterministic scenarios sets &#40;CFT w NY7 &#43; others&#41; to truly stochastic &#40;Stochastic PBR&#41;. &quot;What Intel giveth, the NAIC taketh away.&quot;<sup id="fnref:1"><a href="#fndef:1" class=fnref >[1]</a></sup>.</p> <p>So again, performance matters&#33;</p> <h3 id=readability_and_expressiveness ><a href="#readability_and_expressiveness" class=header-anchor >Readability and Expressiveness</a></h3> <p>Actuaries, even the <a href="/blog/coding-for-the-future/">10x Actuary</a>, aren&#39;t pure computer scientists and computational efficiency has never been <em>so</em> critical that they sacrifice everything else to get it. So the industry never turned to the 40-year king of performance computation, <a href="https://en.wikipedia.org/wiki/Fortran">Fortran</a>. The syntax is very &quot;close to the machine&quot;. I&#39;s a bit rough to read to anyone not well versed.</p> <p>Interestingly, <a href="https://en.wikipedia.org/wiki/APL_&#40;programming_language&#41;">APL</a> took off and was one of the dominant languages used by actuaries before the advent of <a href="/blog/coding-for-the-future/#the_10x_actuary">vendor-supplied modeling solutions</a>.</p> <p>Counting the occurrences of a string looks like this in APL:</p> <pre><code class="julia hljs">csubs←{<span class=hljs-number >0</span>=x←⊃⍸⍺⍷⍵:<span class=hljs-number >0</span> ⋄ <span class=hljs-number >1</span>+⍺∇(¯<span class=hljs-number >1</span>+x+⍴⍺)↓⍵}</code></pre>
<p>whereas in Fortran it would be:</p>
<pre><code class="Fortran hljs"><span class=hljs-function ><span class=hljs-keyword >function</span></span> countsubstring(s1, s2) result(c)
  <span class=hljs-keyword >character</span>(*), <span class=hljs-keyword >intent</span>(<span class=hljs-keyword >in</span>) :: s1, s2
  <span class=hljs-keyword >integer</span> :: c, p, posn
 
  c = <span class=hljs-number >0</span>
  <span class=hljs-keyword >if</span>(len(s2) == <span class=hljs-number >0</span>) <span class=hljs-keyword >return</span>
  p = <span class=hljs-number >1</span>
  <span class=hljs-keyword >do</span> 
    posn = <span class=hljs-built_in >index</span>(s1(p:), s2)
    <span class=hljs-keyword >if</span>(posn == <span class=hljs-number >0</span>) <span class=hljs-keyword >return</span>
    c = c + <span class=hljs-number >1</span>
    p = p + posn + len(s2) - <span class=hljs-number >1</span>
  <span class=hljs-keyword >end</span> <span class=hljs-keyword >do</span>
<span class=hljs-keyword >end</span> <span class=hljs-function ><span class=hljs-keyword >function</span></span></code></pre>
<p>Maybe more readable to the modern eye than APL, but many actuaries would still recognize what&#39;s going on with the first code example.</p>
<p>Why did APL take off for Actuaries and not APL? I think <a href="https://en.wikipedia.org/wiki/Expressive_power_&#37;28computer_science&#37;29">expressiveness</a> and the ability to have a language inspired by mathematical notation were attractive. It&#39;s not pleasant to write a lot of boiler-plate simply to achieve a simple objective. </p>
<p>What is boiler-plate? It&#39;s writing a lot of code supporting the main idea, but straying from a simple mathematical formulation. For example, in high performance object-oriented languages &#40;C#/C&#43;&#43;/Java&#41;, the idiomatic code might involve a special class. See, for example this C# code to count substrings:</p>
<pre><code class="csharp hljs"><span class=hljs-keyword >using</span> System;
 
<span class=hljs-keyword >class</span> <span class=hljs-title >SubStringTestClass</span>
{
   <span class=hljs-function ><span class=hljs-keyword >public</span> <span class=hljs-keyword >static</span> <span class=hljs-built_in >int</span> <span class=hljs-title >CountSubStrings</span>(<span class=hljs-params ><span class=hljs-keyword >this</span> <span class=hljs-built_in >string</span> testString, <span class=hljs-built_in >string</span> testSubstring</span>)</span>
   {
        <span class=hljs-built_in >int</span> count = <span class=hljs-number >0</span>;
 
        <span class=hljs-keyword >if</span> (testString.Contains(testSubstring))
        {
            <span class=hljs-keyword >for</span> (<span class=hljs-built_in >int</span> i = <span class=hljs-number >0</span>; i &lt; testString.Length; i++)
            {
                <span class=hljs-keyword >if</span> (testString.Substring(i).Length &gt;= testSubstring.Length)
                {
                    <span class=hljs-built_in >bool</span> <span class=hljs-keyword >equals</span> = testString.Substring(i, testSubstring.Length).Equals(testSubstring);
                    <span class=hljs-keyword >if</span> (<span class=hljs-keyword >equals</span>)
                    {
                        count++;
                        i += testSubstring.Length - <span class=hljs-number >1</span>;
                    }
                }
            }
        }
        <span class=hljs-keyword >return</span> count;
   }
}</code></pre>
<p>The takeaway from this point, though, is that there is a natural draw towards more expressive, powerful languages than less expressive languages, especially when dealing with mathematically based ideas. So high expressiveness is something we want from a language that solves the LMP.</p>
<h2 id=benchmarks ><a href="#benchmarks" class=header-anchor >Benchmarks</a></h2>
<p>After the original user submitted a proposal, others chimed in and submitted versions in their favorite languages. I have collected those versions, and run them on a consistent set of hardware<sup id="fnref:3"><a href="#fndef:3" class=fnref >[2]</a></sup>.</p>
<p>Some &quot;submissions&quot; were excluded because they involved an entirely different approach, such as <a href="https://en.wikipedia.org/wiki/Memoization">memoizing</a> the function calls<sup id="fnref:2"><a href="#fndef:2" class=fnref >[3]</a></sup>.</p>
<pre><code class="plaintext hljs">Times are nanoseconds:
┌────────────────┬─────────────┬───────────────┬──────────┬──────────┐
│       Language │   Algorithm │ Function Name │   Median │     Mean │
├────────────────┼─────────────┼───────────────┼──────────┼──────────┤
│ R (data.table) │  Vectorized │           npv │ 770554.0 │ 842767.3 │
│              R │  Vectorized │      npv base │   4264.0 │  46617.0 │
│              R │ Accumulator │      npv_loop │   4346.0 │  62275.7 │
│           Rust │ Accumulator │           npv │     24.0 │  missing │
│ Python (NumPy) │  Vectorized │           npv │  missing │  14261.0 │
│         Python │ Accumulator │      npv_loop │  missing │   2314.0 │
│ Python (Numba) │ Accumulator │     npv_numba │  missing │    626.0 │
│          Julia │  Vectorized │          npv1 │    235.3 │    228.2 │
│          Julia │  Vectorized │          npv2 │    235.8 │    218.4 │
│          Julia │ Accumulator │          npv3 │     14.5 │     14.5 │
│          Julia │ Accumulator │          npv4 │     10.8 │     10.8 │
│          Julia │ Accumulator │          npv5 │     11.5 │     11.5 │
│          Julia │ Accumulator │          npv6 │      9.0 │      9.0 │
│          Julia │ Accumulator │          npv7 │      7.9 │      7.9 │
│          Julia │ Accumulator │          npv8 │      7.4 │      7.4 │
│          Julia │ Accumulator │          npv9 │      6.4 │      6.4 │
└────────────────┴─────────────┴───────────────┴──────────┴──────────┘</code></pre>
<p>To aid in visualizing results with such vast different orders of magnitude, this graph includes a physical length comparison to serve as a reference. The computation time is represented by the distance that light travels in the time for the computation to complete &#40;comparing a nanosecond to one foot length <a href="https://www.youtube.com/watch?v&#61;9eyFDBPk4Yw">goes at least back to Admiral Grace Hopper</a>&#41;.</p>
<p><img src="/blog/data/benchmarks.svg" alt="Life Modeling Problem Benchmarks" /></p>
<h2 id=benchmark_discussion ><a href="#benchmark_discussion" class=header-anchor >Benchmark Discussion</a></h2>
<h3 id=takeaway_1 ><a href="#takeaway_1" class=header-anchor >Takeaway #1</a></h3>
<blockquote>
<p>There are a lot of ways to accomplish the same task and and that&#39;s good enough in most cases</p>
</blockquote>
<p>All of the submissions and algorithms above worked, and fast enough that it gave an answer in very little time. And much of the time, the volume of data to process is small enough that it doesn&#39;t matter.</p>
<p>But remember the CUNA Mutual example from above: Let&#39;s say that CUNA&#39;s runtime is already as fast as it can be, and index it to the fastest result in the benchmarks below. The difference between the fastest &quot;couple of days&quot; run and the slowest would be over <strong>721 years</strong>. So it&#39;s important to use tools and approaches that are performant for actuarial work.</p>
<p>So for little one-off tasks it doesn&#39;t make a big difference what tool or algorithm is used. More often than not, your one-off calculations or checks will be done fast enough that it&#39;s not important to be picky. But if wanting to scale your work to a broader application within your company or the industry, I think it&#39;s important to be performance-minded<sup id="fnref:4"><a href="#fndef:4" class=fnref >[4]</a></sup>.</p>
<h3 id=takeaway_2 ><a href="#takeaway_2" class=header-anchor >Takeaway #2</a></h3>
<blockquote>
<p>&quot;If all you have is a dataframe, everything looks like a join&quot;</p>
</blockquote>
<p>I&#39;ve seen this several times in practice. Where a stacked dataframe of mortality rates is joined up with policy data in a complicated series of <code>&#37;&gt;&#37;</code>s &#40;pipes&#41;, <code>inner_joins</code> and <code>mutates</code>.</p>
<p>Don&#39;t get me wrong, I think code is often still a better approach than spreadsheets<sup id="fnref:5"><a href="#fndef:5" class=fnref >[5]</a></sup>.</p>
<p>However, like the old proverb that &quot;if all you have is a hammer, everything looks like a nail&quot; - sometimes the tool you have just isn&#39;t right for the job. That&#39;s the lesson of the R <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html">data.table</a> result above. Even with the fastest dataframe implementation in R, it vastly trails other submissions.</p>
<h4 id=algorithm_choice ><a href="#algorithm_choice" class=header-anchor >Algorithm choice</a></h4>
<p>Getting more refined about the approach, the other thing that is very obvious is that for this recursive type calculation, it&#39;s much more efficient to write a <code>for</code> loop &#40;the <code>Accumulator</code> approach&#41; in every language except for R &#40;where it wants everything to be a vector or dataframe&#41;.</p>
<p>The difference hints at some computational aspects related to arrays that I will touch upon when discussing code examples below. The point for now is that you should consider using tools that give you the flexibility to approach problems in different ways.</p>
<h3 id=takeaway_3 ><a href="#takeaway_3" class=header-anchor >Takeaway #3</a></h3>
<blockquote>
<p>Performance, flexibility, readability: pick one, two, or three depending on the language</p>
</blockquote>
<p>This section ranges from objective &#40;performance metrics&#41; to subjective &#40;my take on flexibility and readability&#41;. My opinions are based on using R heavily for several years ~2011-2015, Python for ~2015-2018, and then primarily switched to Julia in ~2018. I have a lot of experience with VBA, and moderate experience with Javascript, with some educational/introductory background in C, List/Racket, Mathematica, Haskell, and Java.</p>
<h4 id=r ><a href="#r" class=header-anchor >R</a></h4>
<h5 id=performance ><a href="#performance" class=header-anchor >Performance</a></h5>
<p>R was the slowest all-around.</p>
<h5 id=flexibility ><a href="#flexibility" class=header-anchor >Flexibility</a></h5>
<p>R scores well here - <a href="http://adv-r.had.co.nz/Computing-on-the-language.html#nse">non-standard evaluation</a> lets you, essentially, inspect the written code without evaluating it. This is a nice feature that enables a lot of creativity and pleasantries &#40;like ggplot knowing what to label the axes without you telling it&#41;.</p>
<p>R works in notebook environments and from a REPL.</p>
<p>One negative about R&#39;s flexibility is the fact that the language is <a href="https://www.r-project.org/Licenses/AGPL-3">GPL licensed</a>, meaning that there are quite a few restrictions. For example, if you distribute an application that relies on R &#40;e.g. it becomes part of your sales platform distributed to agents&#41; you would need to be able to provide the source code for your application to the said users<sup id="fnref:6"><a href="#fndef:6" class=fnref >[6]</a></sup>. The other languages discussed on this page have much more permissive licenses.</p>
<h5 id=readability ><a href="#readability" class=header-anchor >Readability</a></h5>
<p>R reads pretty easily, with very little boiler plate and terse syntax:</p>
<pre><code class="R hljs"><span class=hljs-comment ># via Houstonwp</span>
q <span class=hljs-operator >&lt;-</span> <span class=hljs-built_in >c</span><span class=hljs-punctuation >(</span><span class=hljs-number >0.001</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.002</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.003</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.003</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.004</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.004</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.005</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.007</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.009</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.011</span><span class=hljs-punctuation >)</span>
w <span class=hljs-operator >&lt;-</span> <span class=hljs-built_in >c</span><span class=hljs-punctuation >(</span><span class=hljs-number >0.05</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.07</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.08</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.10</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.14</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.20</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.20</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.20</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.10</span><span class=hljs-punctuation >,</span><span class=hljs-number >0.04</span><span class=hljs-punctuation >)</span>
P <span class=hljs-operator >&lt;-</span> 100
S <span class=hljs-operator >&lt;-</span> 25000
r <span class=hljs-operator >&lt;-</span> 0.02

base_r_npv <span class=hljs-operator >&lt;-</span> <span class=hljs-keyword >function</span><span class=hljs-punctuation >(</span>q<span class=hljs-punctuation >,</span>w<span class=hljs-punctuation >,</span>P<span class=hljs-punctuation >,</span>S<span class=hljs-punctuation >,</span>r<span class=hljs-punctuation >)</span> <span class=hljs-punctuation >{</span>
  inforce <span class=hljs-operator >&lt;-</span> <span class=hljs-built_in >c</span><span class=hljs-punctuation >(</span><span class=hljs-number >1</span><span class=hljs-punctuation >,</span>head<span class=hljs-punctuation >(</span><span class=hljs-built_in >cumprod</span><span class=hljs-punctuation >(</span><span class=hljs-number >1</span><span class=hljs-operator >-</span>q<span class=hljs-operator >-</span>w<span class=hljs-punctuation >)</span><span class=hljs-punctuation >,</span> <span class=hljs-operator >-</span><span class=hljs-number >1</span><span class=hljs-punctuation >)</span><span class=hljs-punctuation >)</span>
  ncf <span class=hljs-operator >&lt;-</span> inforce <span class=hljs-operator >*</span> P <span class=hljs-operator >-</span> inforce <span class=hljs-operator >*</span> q <span class=hljs-operator >*</span> S
  d <span class=hljs-operator >&lt;-</span> <span class=hljs-punctuation >(</span><span class=hljs-number >1</span><span class=hljs-operator >/</span><span class=hljs-punctuation >(</span><span class=hljs-number >1</span><span class=hljs-operator >+</span>r<span class=hljs-punctuation >)</span><span class=hljs-punctuation >)</span> <span class=hljs-operator >^</span> <span class=hljs-built_in >seq_along</span><span class=hljs-punctuation >(</span>ncf<span class=hljs-punctuation >)</span>
  <span class=hljs-built_in >sum</span><span class=hljs-punctuation >(</span>ncf <span class=hljs-operator >*</span> d<span class=hljs-punctuation >)</span>
<span class=hljs-punctuation >}</span>

base_r_npv<span class=hljs-punctuation >(</span>q<span class=hljs-punctuation >,</span>w<span class=hljs-punctuation >,</span>P<span class=hljs-punctuation >,</span>S<span class=hljs-punctuation >,</span>r<span class=hljs-punctuation >)</span>
<span class=hljs-comment >#&gt; [1] 50.32483</span>
microbenchmark<span class=hljs-operator >::</span>microbenchmark<span class=hljs-punctuation >(</span>base_r_npv<span class=hljs-punctuation >(</span>q<span class=hljs-punctuation >,</span>w<span class=hljs-punctuation >,</span>P<span class=hljs-punctuation >,</span>S<span class=hljs-punctuation >,</span>r<span class=hljs-punctuation >)</span><span class=hljs-punctuation >)</span></code></pre>
<p>R is the oldest of the languages commonly used in actuarial contexts and carries a lot of that weight for better or worse: over several decades, it&#39;s accumulated a sizeable community but is left with a number of rough edges. The data scientist Evan Patterson has written <a href="https://www.epatters.org/post/r-lang/">a nice summary of &quot;the good, the bad, and the ugly&quot; of R</a>.</p>
<h4 id=rust ><a href="#rust" class=header-anchor >Rust</a></h4>
<p>Rust is a newer, statically compiled language designed for performance and safety &#40;in the don&#39;t let your program do memory management mistakes that crash the computer&#41;.</p>
<h5 id=performance__2 ><a href="#performance__2" class=header-anchor >Performance</a></h5>
<p>Rust scores well here, coming second only to Julia.</p>
<h5 id=flexibility__2 ><a href="#flexibility__2" class=header-anchor >Flexibility</a></h5>
<p>Rust is statically compiled &#40;you write script, have computer run script, see results&#41;. It doesn&#39;t have a REPL or ability to be used in an interactive way &#40;e.g. notebook environments&#41;.</p>
<h5 id=readability__2 ><a href="#readability__2" class=header-anchor >Readability</a></h5>
<p>I really like the explicit function contract: you give it various floating point &#40;<code>f64</code>&#41; vectors and numbers, and it returns a float: <code>-&gt; f64</code>.</p>
<p>Other than that it&#39;s pretty straightforward but definitely more verbose than any of the others.</p>
<pre><code class="julia hljs"><span class=hljs-comment >#![feature(test)]</span>
extern crate test;
use test::Bencher;

// Via Paddy Horan
pub fn npv(mortality_rates: &amp;Vec&lt;f64&gt;, lapse_rates: &amp;Vec&lt;f64&gt;, interest_rate: f64, sum_assured: f64, premium: f64, init_pols: f64, term: Option&lt;usize&gt;) -&gt; f64 {

    <span class=hljs-keyword >let</span> term = term.unwrap_or_else(|| mortality_rates.len());
    <span class=hljs-keyword >let</span> mut result = <span class=hljs-number >0.0</span>;
    <span class=hljs-keyword >let</span> mut inforce = init_pols;
    <span class=hljs-keyword >let</span> v: f64 = <span class=hljs-number >1.0</span> / (<span class=hljs-number >1.0</span> + interest_rate);

    <span class=hljs-keyword >for</span> (t, (q, w)) <span class=hljs-keyword >in</span> mortality_rates.iter().zip(lapse_rates).enumerate() {
        <span class=hljs-keyword >let</span> no_deaths = <span class=hljs-keyword >if</span> t &lt; term {inforce * q} <span class=hljs-keyword >else</span> {<span class=hljs-number >0.0</span>};
        <span class=hljs-keyword >let</span> no_lapses = <span class=hljs-keyword >if</span> t &lt; term {inforce * w} <span class=hljs-keyword >else</span> {<span class=hljs-number >0.0</span>};
        <span class=hljs-keyword >let</span> premiums = inforce * premium;
        <span class=hljs-keyword >let</span> claims = no_deaths * sum_assured;
        <span class=hljs-keyword >let</span> net_cashflow = premiums - claims;
        result += net_cashflow * v.powi(t as i32);
        inforce = inforce - no_deaths - no_lapses;
    }

    result
}
<span class=hljs-comment >#[bench]</span>
fn bench_xor_1000_ints(b: &amp;mut Bencher) {

<span class=hljs-keyword >let</span> q: Vec&lt;f64&gt; = vec![<span class=hljs-number >0.001</span>,<span class=hljs-number >0.002</span>,<span class=hljs-number >0.003</span>,<span class=hljs-number >0.003</span>,<span class=hljs-number >0.004</span>,<span class=hljs-number >0.004</span>,<span class=hljs-number >0.005</span>,<span class=hljs-number >0.007</span>,<span class=hljs-number >0.009</span>,<span class=hljs-number >0.011</span>];
<span class=hljs-keyword >let</span> w: Vec&lt;f64&gt; = vec![<span class=hljs-number >0.05</span>,<span class=hljs-number >0.07</span>,<span class=hljs-number >0.08</span>,<span class=hljs-number >0.10</span>,<span class=hljs-number >0.14</span>,<span class=hljs-number >0.20</span>,<span class=hljs-number >0.20</span>,<span class=hljs-number >0.20</span>,<span class=hljs-number >0.10</span>,<span class=hljs-number >0.04</span>];
<span class=hljs-keyword >let</span> p: f64 = <span class=hljs-number >100.0</span>;
<span class=hljs-keyword >let</span> s: f64 = <span class=hljs-number >25000.0</span>;
<span class=hljs-keyword >let</span> r: f64 = <span class=hljs-number >0.02</span>;
    b.iter(|| {
        // use <span class=hljs-string >`test::black_box`</span> to prevent compiler optimizations from disregarding
        // unused values
        test::black_box(npv(&amp;q,&amp;w,r,s,p,<span class=hljs-number >1.0</span>,<span class=hljs-built_in >Some</span>(<span class=hljs-number >10</span>)));
    });
}</code></pre>
<h4 id=python ><a href="#python" class=header-anchor >Python</a></h4>
<h5 id=performance__3 ><a href="#performance__3" class=header-anchor >Performance</a></h5>
<p>With <a href="https://numpy.org/">NumPy</a>, Python was the second fastest <code>Vectorized</code> approach and 3rd place for the <code>Accumulator</code> loop, both cases were still more than an order of magnitude slower than the next place.</p>
<h5 id=flexibility__3 ><a href="#flexibility__3" class=header-anchor >Flexibility</a></h5>
<p>Python wins large points for interactive usage in the REPL, notebooks, and wide variety of environments that support running Python code. However, within the language itself I have to deduct points for the ease of inspecting/evaluating code.</p>
<p>What I mean by that, is that if you look at the code example below, in order to test the code you have to turn it into string and then call the <code>timeit</code> function to read and parse the string. In none of the other tested languages was that sort of boiler-plate required.</p>
<p>Python scores partial points for meta-programming: decorators &#40;<code>@</code> syntax&#41; is syntactic sugar for macro-like modifications to functions, but Python metapgrogramming is <a href="https://softwareengineering.stackexchange.com/a/253377/37060">fundamentally limited</a> by the language design.</p>
<p>Python has perhaps the most robust ecosystem of all the languages discussed here, but in many ways its limiting: once you get deep into an ecosystem &#40;e.g. NumPy&#41;, you are sort of at the mercy of package developers to ensure that the packages are compatible. As a key example, many common types and data structures are not shareable between libraries: there are <a href="https://data-apis.org/">efforts</a> to standardize data types/classes for better compatibility across the Python ecosystem, but may require fundamental changes to the language or ecosystem to accomplish.</p>
<p>On the subject of Python packages: environment and package management in Python is notoriously painful:</p>
<p><img src="https://imgs.xkcd.com/comics/python_environment.png" alt="Python XKCD" /></p>
<h5 id=readability__3 ><a href="#readability__3" class=header-anchor >Readability</a></h5>
<p>One of Python&#39;s seminal features is the pleasant syntax, though opinions differ as to whether the indentation should matter to how your program runs.</p>
<pre><code class="Python hljs"><span class=hljs-keyword >import</span> timeit
setup=<span class=hljs-string >&#x27;&#x27;&#x27;
import numpy as np
q = np.array([0.001,0.002,0.003,0.003,0.004,0.004,0.005,0.007,0.009,0.011])
w = np.array([0.05,0.07,0.08,0.10,0.14,0.20,0.20,0.20,0.10,0.04])
P = 100
S = 25000
r = 0.02
def npv(q,w,P,S,r):
    decrements = np.cumprod(1-q-w)
    inforce = np.empty_like(decrements)
    inforce[:1] = 1
    inforce[1:] = decrements[:-1]
    ncf = inforce * P - inforce * q * S
    t = np.arange(np.size(q))
    d = np.power(1/(1+r), t)
    return np.sum(ncf * d)
&#x27;&#x27;&#x27;</span>
benchmark = <span class=hljs-string >&#x27;&#x27;&#x27;npv(q,w,P,S,r)&#x27;&#x27;&#x27;</span>

<span class=hljs-built_in >print</span>(timeit.timeit(stmt=benchmark,setup=setup,number = <span class=hljs-number >1000000</span>))</code></pre>
<p>To do non standard things like benchmarking &#40;or The benchmarking setup with Python&#39;s <code>timeit</code> is definitely the most painful, needing to wrap the whole thing in a string. And then only get a single number result, without normalizing for the number of runs is very annoying.</p>
<h4 id=julia ><a href="#julia" class=header-anchor >Julia</a></h4>
<h5 id=performance__4 ><a href="#performance__4" class=header-anchor >Performance</a></h5>
<p>The fastest language with both algorithms.</p>
<h5 id=flexibility__4 ><a href="#flexibility__4" class=header-anchor >Flexibility</a></h5>
<p>Available in a variety of environments, include the standard interactive ones like the REPL and notebooks. One key differentiator is the <a href="https://www.nature.com/articles/d41586-021-01174-w">reactive notebook</a> environment, <a href="https://github.com/fonsp/Pluto.jl">Pluto.jl</a> where notebook cells understand and interact with one-another.</p>
<p>Julia packages are also <a href="https://www.youtube.com/watch?v&#61;kc9HwsxE1OY">notoriously cross-functional</a>, so unlike Python &#40;e.g. NumPy&#41; or R &#40;e.g. Tidyverse&#41;, tightly coupled specialty-ecosystems have not evolved in Julia.</p>
<p>Julia is MIT licensed, as are many of the community packages &#40;including JuliaActuary&#39;s&#41;. This license is very permissive and is likely to cause the least issue compared with other licenses discussed on this page.</p>
<p>The ability to introspect code is one of Julia&#39;s superpowers </p>
<h5 id=readability__4 ><a href="#readability__4" class=header-anchor >Readability</a></h5>
<p>Julia scores well here, but gets dinged in my mind for a couple of things:</p>
<ul>
<li><p>all of those dots&#33;</p>

<li><p>the weird <code>@benchmark</code> and dollar signs &#40;<code>&#36;</code>s&#41;</p>

</ul>
<p>The former is actually a very powerful concept/tool called <a href="https://docs.julialang.org/en/v1/manual/arrays/#Broadcasting">broadcasting</a>. Kind of like R &#40;where everything is a vector and will combine in vector-like ways&#41;. Julia lets you both worlds: really effective scalars and highly efficient vector operations. Once you know what it does, it&#39;s hard to think of a shorter/more concise way to express it than the dot &#40;<code>.</code>&#41;.</p>
<p>The latter, <code>@benchmark</code> is a way to get Julia to work with the code itself, again kind of like R does. <code>@benchmark</code> is a <a href="https://docs.julialang.org/en/v1/manual/metaprogramming/#man-macros">macro</a> that will run a really comprehensive and informative benchmarking set on the code given.</p>
<p>The <code>Vectorized</code> version:</p>
<pre><code class="Julia hljs"><span class=hljs-keyword >using</span> BenchmarkTools

q = [<span class=hljs-number >0.001</span>,<span class=hljs-number >0.002</span>,<span class=hljs-number >0.003</span>,<span class=hljs-number >0.003</span>,<span class=hljs-number >0.004</span>,<span class=hljs-number >0.004</span>,<span class=hljs-number >0.005</span>,<span class=hljs-number >0.007</span>,<span class=hljs-number >0.009</span>,<span class=hljs-number >0.011</span>]
w = [<span class=hljs-number >0.05</span>,<span class=hljs-number >0.07</span>,<span class=hljs-number >0.08</span>,<span class=hljs-number >0.10</span>,<span class=hljs-number >0.14</span>,<span class=hljs-number >0.20</span>,<span class=hljs-number >0.20</span>,<span class=hljs-number >0.20</span>,<span class=hljs-number >0.10</span>,<span class=hljs-number >0.04</span>]
P = <span class=hljs-number >100</span>
S = <span class=hljs-number >25000</span>
r = <span class=hljs-number >0.02</span>

<span class=hljs-keyword >function</span> npv1(q,w,P,S,r) 
	inforce = [<span class=hljs-number >1.</span>; cumprod(<span class=hljs-number >1</span> .- q .- w)[<span class=hljs-number >1</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>]] 
  	ncf = inforce .* P .- inforce .* q .* S
 	d = (<span class=hljs-number >1</span> ./ (<span class=hljs-number >1</span> + r)) .^ (<span class=hljs-number >1</span>:length(ncf))
  	<span class=hljs-keyword >return</span> sum(ncf .* d)
<span class=hljs-keyword >end</span>

<span class=hljs-meta >@benchmark</span> npv($q,$w,$P,$S,$r)</code></pre>
<p>And the <code>Accumulator</code> version:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >function</span> npv5(q,w,P,S,r,term=<span class=hljs-literal >nothing</span>)
    term = term === <span class=hljs-literal >nothing</span> ? length(q) : term
    inforce = <span class=hljs-number >1.0</span>
    result = <span class=hljs-number >0.0</span>
    v = (<span class=hljs-number >1</span> / ( <span class=hljs-number >1</span> + r))
    v_t = v
    <span class=hljs-keyword >for</span> (q,w,_) <span class=hljs-keyword >in</span> zip(q,w,<span class=hljs-number >1</span>:term)
        result += inforce * (P - S * q) * v_t
        inforce -= inforce * q + inforce * w
        v_t *= v
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span> result
<span class=hljs-keyword >end</span></code></pre>
<h2 id=more_flexibility_more_performance_from_julia ><a href="#more_flexibility_more_performance_from_julia" class=header-anchor >More flexibility, more performance from Julia</a></h2>
<p>I wanted to go a little bit deeper and show how 1&#41; Julia just runs fast even if your not explicitly focused on performance. But for where it <em>really</em> matters, you can go even deeper. This is a little advanced, but I think it can be useful to introduce some basics as to why some languages and approaches are going to be fundamentally slower than others.</p>
<p>Notes: The accumulator approach vectors and allocations talk about stack/heap? pick a faster approach and explain why it&#39;s even faster.</p>
<h2 id=colophon ><a href="#colophon" class=header-anchor >Colophon</a></h2>
<h3 id=code ><a href="#code" class=header-anchor >Code</a></h3>
<p>All of the benchmarked code can be found in the <a href="https://github.com/JuliaActuary/Learn/tree/master/LifeModelingProblemBenchmarks">JuliaActuary Learn repository</a>. Please file an issue or submit a PR request there for issues/suggestions.</p>
<h3 id=hardware ><a href="#hardware" class=header-anchor >Hardware</a></h3>
<p>MacBook Air &#40;M1, 2020&#41;</p>
<h3 id=software ><a href="#software" class=header-anchor >Software</a></h3>
<p>All languages/libraries are Mac M1 native unless otherwise noted</p>
<h4 id=julia__2 ><a href="#julia__2" class=header-anchor >Julia</a></h4>
<pre><code class="julia hljs">Julia Version <span class=hljs-number >1.7</span><span class=hljs-number >.0</span>-DEV<span class=hljs-number >.938</span>
Commit <span class=hljs-number >2</span>b4c088ee7* (<span class=hljs-number >2021</span>-<span class=hljs-number >04</span>-<span class=hljs-number >16</span> <span class=hljs-number >20</span>:<span class=hljs-number >37</span> UTC)
Platform Info:
  OS: macOS (arm64-apple-darwin20<span class=hljs-number >.3</span><span class=hljs-number >.0</span>)
  CPU: Apple M1
  WORD_SIZE: <span class=hljs-number >64</span>
  LIBM: libopenlibm
  LLVM: libLLVM-<span class=hljs-number >11.0</span><span class=hljs-number >.1</span> (ORCJIT, cyclone)</code></pre>
<h4 id=rust__2 ><a href="#rust__2" class=header-anchor >Rust</a></h4>
<pre><code class="julia hljs"><span class=hljs-number >1.53</span><span class=hljs-number >.0</span>-nightly (b0c818c5e <span class=hljs-number >2021</span>-<span class=hljs-number >04</span>-<span class=hljs-number >16</span>)</code></pre>
<h4 id=python__2 ><a href="#python__2" class=header-anchor >Python</a></h4>
<pre><code class="julia hljs">Python <span class=hljs-number >3.9</span><span class=hljs-number >.4</span> (default, Apr  <span class=hljs-number >4</span> <span class=hljs-number >2021</span>, <span class=hljs-number >17</span>:<span class=hljs-number >42</span>:<span class=hljs-number >23</span>) 
[Clang <span class=hljs-number >12.0</span><span class=hljs-number >.0</span> (clang-<span class=hljs-number >1200.0</span><span class=hljs-number >.32</span><span class=hljs-number >.29</span>)] on darwin</code></pre>
<h2 id=footnotes ><a href="#footnotes" class=header-anchor >Footnotes</a></h2>
<p><sup id="fnref:1"><a href="#fndef:1" class=fnref >[1]</a></sup> A take on <a href="https://en.wikipedia.org/wiki/Andy_and_Bill&#37;27s_law">Andy and Bill&#39;s law</a></p>
<p><sup id="fnref:2"><a href="#fndef:2" class=fnref >[3]</a></sup> If benchmarking memoization, it&#39;s essentially benchmarking how long it takes to perform hashing in a language. While interesting, especially in the context of <a href="https://scattered-thoughts.net/writing/an-opinionated-map-of-incremental-and-streaming-systems">incremental computing</a>, it&#39;s not the core issue at hand. Incremental computing libraries exist for all of the modern languages discussed here.</p>
<p><sup id="fnref:3"><a href="#fndef:3" class=fnref >[2]</a></sup> Note that not all languages have both a mean and median result in their benchmarking libraries. Mean is a better representation for a garbage-collected modern language, because sometimes the computation just takes longer than the median result. Where the mean is not available in the graph below, median is substituted.</p>
<p><sup id="fnref:4"><a href="#fndef:4" class=fnref >[4]</a></sup> Don&#39;t <a href="https://en.wikipedia.org/wiki/Program_optimization#When_to_optimizer">prematurely optimize</a>. But in the long run avoid, <a href="https://www.nature.com/articles/d41586-019-02310-3">re-writing your code in a faster language too many times&#33;</a></p>
<p><sup id="fnref:5"><a href="#fndef:5" class=fnref >[5]</a></sup>  I&#39;ve seen 50&#43; line, irregular Excel formulas. To Nick: it probably started out as a good idea but it was a beast to understand and modify&#33; At least with code you can look at the code with variable names and syntax highlighting&#33; Comments, if you are lucky&#33;</p>
<p><sup id="fnref:6"><a href="#fndef:6" class=fnref >[6]</a></sup> This is not legal advice, consult a lawyer for more details.</p>
<div class=page-foot >
  The packages in JuliaActuary are open-source and liberally licensed (MIT License) to allow wide private and commercial
  usage of the packages, like the base Julia language and many other packages in the ecosystem. See <a href="/terms/" >terms of this site.</a>
  
  
  <div class=copyright >
    &copy; Alec Loudenback. Last modified: September 13, 2022. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and <a href="https://julialang.org">Julia</a>.
  </div>
</div></div>
    
    
        


    
    <script data-goatcounter="https://juliaactuary.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>